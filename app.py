import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import calendar
import gspread
from google.oauth2.service_account import Credentials
from oauth2client.service_account import ServiceAccountCredentials
import openai
import os
import json

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="åºƒå‘Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã‚·ã‚¹ãƒ†ãƒ ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¡¨ç¤º
st.sidebar.title("åºƒå‘Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã‚·ã‚¹ãƒ†ãƒ ")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'data' not in st.session_state:
    st.session_state['data'] = None
if 'analysis_result' not in st.session_state:
    st.session_state['analysis_result'] = None

# Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€é–¢æ•°
def load_data_from_gsheet(url, sheet_name):
    try:
        st.sidebar.info("Google Spreadsheetã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
        
        # Google APIã®èªè¨¼ã‚¹ã‚³ãƒ¼ãƒ—
        scope = ['https://spreadsheets.google.com/feeds',
                'https://www.googleapis.com/auth/drive']
        
        # èªè¨¼æƒ…å ±ã®å–å¾—ï¼ˆå®Ÿéš›ã®ãƒ‡ãƒ—ãƒ­ã‚¤æ™‚ã«ã¯ã€ã‚ˆã‚Šå®‰å…¨ãªæ–¹æ³•ã§èªè¨¼æƒ…å ±ã‚’ç®¡ç†ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼‰
        # Streamlit Secretsã‚’ä½¿ç”¨ã™ã‚‹å ´åˆ
        if 'gcp_service_account' in st.secrets:
            credentials_info = st.secrets['gcp_service_account']
            credentials = ServiceAccountCredentials.from_json_keyfile_dict(credentials_info, scope)
        else:
            # ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç”¨ï¼ˆã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ï¼‰
            # æ³¨æ„: ã“ã®æ–¹æ³•ã¯æœ¬ç•ªç’°å¢ƒã§ã¯ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„
            st.sidebar.warning("ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚­ãƒ¼ãŒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚credentials.jsonãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ã§ã™ã€‚")
            credentials = ServiceAccountCredentials.from_json_keyfile_name('credentials.json', scope)
        
        client = gspread.authorize(credentials)
        
        # URLã‹ã‚‰ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’é–‹ã
        spreadsheet_id = url.split('/d/')[1].split('/')[0]
        sheet = client.open_by_key(spreadsheet_id).worksheet(sheet_name)
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã«èª­ã¿è¾¼ã‚€
        data = sheet.get_all_records()
        df = pd.DataFrame(data)
        
        # ãƒ‡ãƒ¼ã‚¿å‹ã®å¤‰æ›
        numeric_cols = ['Impressions', 'Clicks', 'Cost', 'Conversions']
        for col in numeric_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # æ—¥ä»˜ã®å¤‰æ›
        if 'Date' in df.columns:
            df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
            
        # æ¬ æå€¤ã®ãƒã‚§ãƒƒã‚¯ã¨å‡¦ç†
        if df.isna().sum().sum() > 0:
            st.sidebar.warning(f"ãƒ‡ãƒ¼ã‚¿ã«æ¬ æå€¤ãŒ {df.isna().sum().sum()} ä»¶ã‚ã‚Šã¾ã™ã€‚")
            # æ•°å€¤å‹ã®æ¬ æå€¤ã‚’0ã«ç½®æ›
            for col in numeric_cols:
                if col in df.columns:
                    df[col] = df[col].fillna(0)
        
        st.sidebar.success(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df)} è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        
        return df
    
    except Exception as e:
        st.sidebar.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return None

# æ´¾ç”ŸæŒ‡æ¨™ã®è¨ˆç®—é–¢æ•°
def calculate_derived_metrics(df):
    # 0é™¤ç®—ã‚’é¿ã‘ã‚‹ãŸã‚ã®é–¢æ•°
    def safe_divide(x, y):
        return np.where(y != 0, x / y, 0)
    
    # æ´¾ç”ŸæŒ‡æ¨™ã®è¨ˆç®—
    if 'Impressions' in df.columns and 'Clicks' in df.columns:
        df['CTR'] = safe_divide(df['Clicks'], df['Impressions']) * 100
    
    if 'Clicks' in df.columns and 'Conversions' in df.columns:
        df['CVR'] = safe_divide(df['Conversions'], df['Clicks']) * 100
    
    if 'Clicks' in df.columns and 'Cost' in df.columns:
        df['CPC'] = safe_divide(df['Cost'], df['Clicks'])
    
    if 'Conversions' in df.columns and 'Cost' in df.columns:
        df['CPA'] = safe_divide(df['Cost'], df['Conversions'])
    
    if 'Impressions' in df.columns and 'Cost' in df.columns:
        df['CPM'] = safe_divide(df['Cost'], df['Impressions']) * 1000
    
    return df

# ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹é–¢æ•°ï¼ˆæœŸé–“æŒ‡å®šï¼‰
def filter_data_by_date(df, start_date, end_date):
    if 'Date' not in df.columns:
        st.error("ãƒ‡ãƒ¼ã‚¿ã«æ—¥ä»˜åˆ—ãŒã‚ã‚Šã¾ã›ã‚“")
        return df
    
    filtered_df = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]
    return filtered_df

# æœŸé–“ã”ã¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’é›†è¨ˆã™ã‚‹é–¢æ•°
def aggregate_data_by_period(df, group_by_cols=['ServiceNameJA']):
    # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
    required_cols = ['Impressions', 'Clicks', 'Cost', 'Conversions']
    for col in required_cols:
        if col not in df.columns:
            st.error(f"å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ {col} ãŒãƒ‡ãƒ¼ã‚¿ã«ã‚ã‚Šã¾ã›ã‚“")
            return None
    
    # ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã¨é›†è¨ˆ
    agg_dict = {
        'Impressions': 'sum',
        'Clicks': 'sum',
        'Cost': 'sum',
        'Conversions': 'sum'
    }
    
    # é›†è¨ˆ
    agg_df = df.groupby(group_by_cols).agg(agg_dict).reset_index()
    
    # æ´¾ç”ŸæŒ‡æ¨™ã®è¨ˆç®—
    agg_df = calculate_derived_metrics(agg_df)
    
    return agg_df

# æœŸé–“æ¯”è¼ƒã®ãŸã‚ã®åˆ†æé–¢æ•°
def compare_periods(current_df, previous_df, group_by_cols=['ServiceNameJA']):
    """
    äºŒã¤ã®æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¯”è¼ƒã—ã¦åˆ†æçµæœã‚’è¿”ã™
    
    Parameters:
    current_df (DataFrame): å½“æœŸã®ãƒ‡ãƒ¼ã‚¿
    previous_df (DataFrame): å‰æœŸã®ãƒ‡ãƒ¼ã‚¿
    group_by_cols (list): ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã™ã‚‹ã‚«ãƒ©ãƒ 
    
    Returns:
    dict: åˆ†æçµæœã‚’å«ã‚€è¾æ›¸
    """
    # ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã¨é›†è¨ˆ
    current_agg = aggregate_data_by_period(current_df, group_by_cols)
    previous_agg = aggregate_data_by_period(previous_df, group_by_cols)
    
    if current_agg is None or previous_agg is None:
        return None
    
    # åˆè¨ˆå€¤ã®è¨ˆç®—
    current_total = current_agg.sum(numeric_only=True).to_dict()
    previous_total = previous_agg.sum(numeric_only=True).to_dict()
    
    # æ—¥æ•°ã®è¨ˆç®—ï¼ˆæ—¥å¹³å‡å€¤ã®è¨ˆç®—ç”¨ï¼‰
    if 'Date' in current_df.columns and 'Date' in previous_df.columns:
        current_days = (current_df['Date'].max() - current_df['Date'].min()).days + 1
        previous_days = (previous_df['Date'].max() - previous_df['Date'].min()).days + 1
    else:
        current_days = 30  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
        previous_days = 30  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    
    # 1. CVå¢—æ¸›ã®å¯„ä¸åº¦åˆ†æ
    cv_contribution = analyze_cv_contribution(current_agg, previous_agg, group_by_cols)
    
    # 2. CPAå¤‰åŒ–è¦å› åˆ†æ
    cpa_change_factors = analyze_cpa_change_factors(current_agg, previous_agg, group_by_cols)
    
    # 3. åª’ä½“ã‚°ãƒ«ãƒ¼ãƒ—ãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
    media_patterns = analyze_media_patterns(current_agg, previous_agg, group_by_cols)
    
    # åˆ†æçµæœã‚’è¾æ›¸ã«ã¾ã¨ã‚ã‚‹
    result = {
        'current_agg': current_agg,
        'previous_agg': previous_agg,
        'current_total': current_total,
        'previous_total': previous_total,
        'current_days': current_days,
        'previous_days': previous_days,
        'cv_contribution': cv_contribution,
        'cpa_change_factors': cpa_change_factors,
        'media_patterns': media_patterns
    }
    
    return result

# 1. CVå¢—æ¸›ã®å¯„ä¸åº¦åˆ†æ
def analyze_cv_contribution(current_agg, previous_agg, group_by_cols=['ServiceNameJA']):
    """
    CVå¢—æ¸›ã®å¯„ä¸åº¦åˆ†æã‚’è¡Œã†
    
    Parameters:
    current_agg (DataFrame): å½“æœŸã®é›†è¨ˆãƒ‡ãƒ¼ã‚¿
    previous_agg (DataFrame): å‰æœŸã®é›†è¨ˆãƒ‡ãƒ¼ã‚¿
    group_by_cols (list): ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ãŸã‚«ãƒ©ãƒ 
    
    Returns:
    DataFrame: å¯„ä¸åº¦åˆ†æçµæœ
    """
    # åª’ä½“åãªã©ã®ãƒãƒƒãƒãƒ³ã‚°ç”¨ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨­å®š
    current_df = current_agg.set_index(group_by_cols)
    previous_df = previous_agg.set_index(group_by_cols)
    
    # å…±é€šã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
    common_indices = set(current_df.index) & set(previous_df.index)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®æº–å‚™
    contribution_data = []
    
    # å…¨ä½“ã®CVå¤‰åŒ–é‡ã‚’è¨ˆç®—
    total_current_cv = current_df['Conversions'].sum()
    total_previous_cv = previous_df['Conversions'].sum()
    total_cv_change = total_current_cv - total_previous_cv
    
    # å„åª’ä½“ã®CVå¤‰åŒ–ã¨å¯„ä¸ç‡ã‚’è¨ˆç®—
    for idx in common_indices:
        current_cv = current_df.loc[idx, 'Conversions']
        previous_cv = previous_df.loc[idx, 'Conversions']
        cv_change = current_cv - previous_cv
        
        # å¯„ä¸ç‡ã®è¨ˆç®— (å…¨ä½“ã®CVå¤‰åŒ–ãŒ0ã®å ´åˆã¯ç‰¹åˆ¥å‡¦ç†)
        if total_cv_change != 0:
            contribution_rate = (cv_change / total_cv_change) * 100
        else:
            contribution_rate = 0 if cv_change == 0 else float('inf') if cv_change > 0 else float('-inf')
        
        # æ–°è¦ã¾ãŸã¯çµ‚äº†ã—ãŸåª’ä½“ã®å ´åˆ
        entry_status = "ç¶™ç¶š"
        if idx not in previous_df.index:
            entry_status = "æ–°è¦"
            previous_cv = 0
        elif idx not in current_df.index:
            entry_status = "çµ‚äº†"
            current_cv = 0
        
        contribution_data.append({
            'index': idx,
            'previous_cv': previous_cv,
            'current_cv': current_cv,
            'cv_change': cv_change,
            'contribution_rate': contribution_rate,
            'entry_status': entry_status
        })
    
    # æ–°è¦è¿½åŠ ã•ã‚ŒãŸåª’ä½“ã®å‡¦ç†
    for idx in set(current_df.index) - set(previous_df.index):
        current_cv = current_df.loc[idx, 'Conversions']
        cv_change = current_cv
        
        # å¯„ä¸ç‡ã®è¨ˆç®—
        if total_cv_change != 0:
            contribution_rate = (cv_change / total_cv_change) * 100
        else:
            contribution_rate = float('inf') if cv_change > 0 else float('-inf')
        
        contribution_data.append({
            'index': idx,
            'previous_cv': 0,
            'current_cv': current_cv,
            'cv_change': cv_change,
            'contribution_rate': contribution_rate,
            'entry_status': "æ–°è¦"
        })
    
    # çµ‚äº†ã—ãŸåª’ä½“ã®å‡¦ç†
    for idx in set(previous_df.index) - set(current_df.index):
        previous_cv = previous_df.loc[idx, 'Conversions']
        cv_change = -previous_cv
        
        # å¯„ä¸ç‡ã®è¨ˆç®—
        if total_cv_change != 0:
            contribution_rate = (cv_change / total_cv_change) * 100
        else:
            contribution_rate = float('inf') if cv_change > 0 else float('-inf')
        
        contribution_data.append({
            'index': idx,
            'previous_cv': previous_cv,
            'current_cv': 0,
            'cv_change': cv_change,
            'contribution_rate': contribution_rate,
            'entry_status': "çµ‚äº†"
        })
    
    # DataFrameã«å¤‰æ›
    contribution_df = pd.DataFrame(contribution_data)
    
    # ãƒãƒ«ãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å ´åˆã®å‡¦ç†
    if len(group_by_cols) > 1:
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®åˆ†è§£
        for i, col in enumerate(group_by_cols):
            contribution_df[col] = contribution_df['index'].apply(lambda x: x[i])
    else:
        # å˜ä¸€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å ´åˆ
        contribution_df[group_by_cols[0]] = contribution_df['index']
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆ—ã‚’å‰Šé™¤
    contribution_df = contribution_df.drop(columns=['index'])
    
    # å¯„ä¸ç‡ã®çµ¶å¯¾å€¤ã§é™é †ã‚½ãƒ¼ãƒˆ
    contribution_df['abs_contribution'] = contribution_df['contribution_rate'].abs()
    contribution_df = contribution_df.sort_values('abs_contribution', ascending=False)
    contribution_df = contribution_df.drop(columns=['abs_contribution'])
    
    return contribution_df

# 2. CPAå¤‰åŒ–è¦å› åˆ†æ
def analyze_cpa_change_factors(current_agg, previous_agg, group_by_cols=['ServiceNameJA']):
    """
    CPAå¤‰åŒ–ã®è¦å› åˆ†æã‚’è¡Œã†
    
    Parameters:
    current_agg (DataFrame): å½“æœŸã®é›†è¨ˆãƒ‡ãƒ¼ã‚¿
    previous_agg (DataFrame): å‰æœŸã®é›†è¨ˆãƒ‡ãƒ¼ã‚¿
    group_by_cols (list): ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ãŸã‚«ãƒ©ãƒ 
    
    Returns:
    DataFrame: CPAå¤‰åŒ–è¦å› åˆ†æçµæœ
    """
    # åª’ä½“åãªã©ã®ãƒãƒƒãƒãƒ³ã‚°ç”¨ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨­å®š
    current_df = current_agg.set_index(group_by_cols)
    previous_df = previous_agg.set_index(group_by_cols)
    
    # å…±é€šã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
    common_indices = set(current_df.index) & set(previous_df.index)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®æº–å‚™
    factor_data = []
    
    # å„åª’ä½“ã®CPAå¤‰åŒ–è¦å› ã‚’åˆ†æ
    for idx in common_indices:
        # å‰æœŸãƒ»å½“æœŸã®CPA, CVR, CPCã‚’å–å¾—
        try:
            current_cpa = current_df.loc[idx, 'CPA']
            previous_cpa = previous_df.loc[idx, 'CPA']
            
            current_cvr = current_df.loc[idx, 'CVR']
            previous_cvr = previous_df.loc[idx, 'CVR']
            
            current_cpc = current_df.loc[idx, 'CPC']
            previous_cpc = previous_df.loc[idx, 'CPC']
            
            current_cpm = current_df.loc[idx, 'CPM']
            previous_cpm = previous_df.loc[idx, 'CPM']
            
            current_ctr = current_df.loc[idx, 'CTR']
            previous_ctr = previous_df.loc[idx, 'CTR']
            
            # å¤‰åŒ–ç‡ã®è¨ˆç®—
            cpa_change_rate = ((current_cpa - previous_cpa) / previous_cpa) * 100 if previous_cpa != 0 else float('inf')
            cvr_change_rate = ((current_cvr - previous_cvr) / previous_cvr) * 100 if previous_cvr != 0 else float('inf')
            cpc_change_rate = ((current_cpc - previous_cpc) / previous_cpc) * 100 if previous_cpc != 0 else float('inf')
            cpm_change_rate = ((current_cpm - previous_cpm) / previous_cpm) * 100 if previous_cpm != 0 else float('inf')
            ctr_change_rate = ((current_ctr - previous_ctr) / previous_ctr) * 100 if previous_ctr != 0 else float('inf')
            
            # ä¸»è¦å› åˆ¤å®š
            cvr_factor = abs(cvr_change_rate)
            cpc_factor = abs(cpc_change_rate)
            
            if cvr_factor > cpc_factor:
                main_factor = "CVR"
                secondary_factor = None
            else:
                main_factor = "CPC"
                # å‰¯è¦å› åˆ¤å®š
                if abs(cpm_change_rate) > abs(ctr_change_rate):
                    secondary_factor = "CPM"
                else:
                    secondary_factor = "CTR"
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®å¤‰åŒ–ã®èª¬æ˜ã‚’ç”Ÿæˆ
            if current_cpa < previous_cpa:
                performance_change = "æ”¹å–„"
            else:
                performance_change = "æ‚ªåŒ–"
            
            factor_data.append({
                'index': idx,
                'previous_cpa': previous_cpa,
                'current_cpa': current_cpa,
                'cpa_change_rate': cpa_change_rate,
                'cvr_change_rate': cvr_change_rate,
                'cpc_change_rate': cpc_change_rate,
                'cpm_change_rate': cpm_change_rate,
                'ctr_change_rate': ctr_change_rate,
                'main_factor': main_factor,
                'secondary_factor': secondary_factor,
                'performance_change': performance_change
            })
        
        except Exception as e:
            st.warning(f"CPAå¤‰åŒ–è¦å› åˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼ˆ{idx}ï¼‰: {str(e)}")
            continue
    
    # DataFrameã«å¤‰æ›
    factor_df = pd.DataFrame(factor_data)
    
    # ãƒãƒ«ãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å ´åˆã®å‡¦ç†
    if len(group_by_cols) > 1:
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®åˆ†è§£
        for i, col in enumerate(group_by_cols):
            factor_df[col] = factor_df['index'].apply(lambda x: x[i])
    else:
        # å˜ä¸€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å ´åˆ
        factor_df[group_by_cols[0]] = factor_df['index']
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆ—ã‚’å‰Šé™¤
    factor_df = factor_df.drop(columns=['index'])
    
    # CPAå¤‰åŒ–ç‡ã®çµ¶å¯¾å€¤ã§é™é †ã‚½ãƒ¼ãƒˆ
    factor_df['abs_cpa_change'] = factor_df['cpa_change_rate'].abs()
    factor_df = factor_df.sort_values('abs_cpa_change', ascending=False)
    factor_df = factor_df.drop(columns=['abs_cpa_change'])
    
    return factor_df

# 3. åª’ä½“ã‚°ãƒ«ãƒ¼ãƒ—ãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
def analyze_media_patterns(current_agg, previous_agg, group_by_cols=['ServiceNameJA']):
    """
    åª’ä½“ã®ã‚°ãƒ«ãƒ¼ãƒ—ãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã‚’è¡Œã†
    
    Parameters:
    current_agg (DataFrame): å½“æœŸã®é›†è¨ˆãƒ‡ãƒ¼ã‚¿
    previous_agg (DataFrame): å‰æœŸã®é›†è¨ˆãƒ‡ãƒ¼ã‚¿
    group_by_cols (list): ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ãŸã‚«ãƒ©ãƒ 
    
    Returns:
    dict: ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ã®åª’ä½“ã‚°ãƒ«ãƒ¼ãƒ—
    """
    # åª’ä½“åãªã©ã®ãƒãƒƒãƒãƒ³ã‚°ç”¨ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨­å®š
    current_df = current_agg.set_index(group_by_cols)
    previous_df = previous_agg.set_index(group_by_cols)
    
    # å…±é€šã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
    common_indices = set(current_df.index) & set(previous_df.index)
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†é¡ç”¨ã®è¾æ›¸
    patterns = {
        'success': [],  # CVå¢—åŠ ã‹ã¤CPAæ”¹å–„
        'growth': [],   # CVå¢—åŠ ã‹ã¤CPAæ‚ªåŒ–
        'efficiency': [], # CVæ¸›å°‘ã‹ã¤CPAæ”¹å–„
        'issue': []     # CVæ¸›å°‘ã‹ã¤CPAæ‚ªåŒ–
    }
    
    pattern_data = []
    
    # å„åª’ä½“ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ
    for idx in common_indices:
        try:
            current_cv = current_df.loc[idx, 'Conversions']
            previous_cv = previous_df.loc[idx, 'Conversions']
            
            current_cpa = current_df.loc[idx, 'CPA']
            previous_cpa = previous_df.loc[idx, 'CPA']
            
            # CVå¢—æ¸›ã¨CPAæ”¹å–„ãƒ»æ‚ªåŒ–ã®åˆ¤å®š
            cv_change = current_cv - previous_cv
            cpa_change = current_cpa - previous_cpa
            
            # åˆ¤å®šçµæœã«åŸºã¥ã„ã¦ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†é¡
            if cv_change >= 0 and cpa_change <= 0:
                pattern = 'success'  # CVå¢—åŠ ã‹ã¤CPAæ”¹å–„
            elif cv_change >= 0 and cpa_change > 0:
                pattern = 'growth'   # CVå¢—åŠ ã‹ã¤CPAæ‚ªåŒ–
            elif cv_change < 0 and cpa_change <= 0:
                pattern = 'efficiency' # CVæ¸›å°‘ã‹ã¤CPAæ”¹å–„
            else:  # cv_change < 0 and cpa_change > 0
                pattern = 'issue'    # CVæ¸›å°‘ã‹ã¤CPAæ‚ªåŒ–
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³ã«è¿½åŠ 
            patterns[pattern].append(idx)
            
            pattern_data.append({
                'index': idx,
                'previous_cv': previous_cv,
                'current_cv': current_cv,
                'cv_change': cv_change,
                'previous_cpa': previous_cpa,
                'current_cpa': current_cpa,
                'cpa_change': cpa_change,
                'pattern': pattern
            })
        
        except Exception as e:
            st.warning(f"åª’ä½“ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼ˆ{idx}ï¼‰: {str(e)}")
            continue
    
    # DataFrameã«å¤‰æ›
    pattern_df = pd.DataFrame(pattern_data)
    
    # ãƒãƒ«ãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å ´åˆã®å‡¦ç†
    if len(group_by_cols) > 1:
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®åˆ†è§£
        for i, col in enumerate(group_by_cols):
            pattern_df[col] = pattern_df['index'].apply(lambda x: x[i])
    else:
        # å˜ä¸€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å ´åˆ
        pattern_df[group_by_cols[0]] = pattern_df['index']
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆ—ã‚’å‰Šé™¤
    pattern_df = pattern_df.drop(columns=['index'])
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³åã‚’æ—¥æœ¬èªã«å¤‰æ›
    pattern_names = {
        'success': 'æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆCVå¢—åŠ ã‹ã¤CPAæ”¹å–„ï¼‰',
        'growth': 'æˆé•·é‡è¦–ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆCVå¢—åŠ ã‹ã¤CPAæ‚ªåŒ–ï¼‰',
        'efficiency': 'åŠ¹ç‡é‡è¦–ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆCVæ¸›å°‘ã‹ã¤CPAæ”¹å–„ï¼‰',
        'issue': 'èª²é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆCVæ¸›å°‘ã‹ã¤CPAæ‚ªåŒ–ï¼‰'
    }
    
    pattern_df['pattern_name'] = pattern_df['pattern'].map(pattern_names)
    
    return {
        'pattern_groups': patterns,
        'pattern_df': pattern_df
    }

# åˆ†æçµæœã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”¨ã«æ•´å½¢ã™ã‚‹é–¢æ•°
def format_prompt_data(analysis_result):
    """
    åˆ†æçµæœã‚’ChatGPTç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ‡ãƒ¼ã‚¿ã«æ•´å½¢ã™ã‚‹
    
    Parameters:
    analysis_result (dict): åˆ†æçµæœ
    
    Returns:
    dict: æ•´å½¢ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿
    """
    # æœŸé–“ã®ç·æ‹¬ãƒ‡ãƒ¼ã‚¿
    current_total = analysis_result['current_total']
    previous_total = analysis_result['previous_total']
    
    # æ—¥ä»˜æƒ…å ±ï¼ˆã‚ã‚Œã°ï¼‰
    current_days = analysis_result.get('current_days', 30)
    previous_days = analysis_result.get('previous_days', 30)
    
    # CVå¢—æ¸›ã®å¯„ä¸åº¦åˆ†æ
    cv_contribution = analysis_result['cv_contribution']
    
    # CPAå¤‰åŒ–è¦å› åˆ†æ
    cpa_change_factors = analysis_result['cpa_change_factors']
    
    # åª’ä½“ã‚°ãƒ«ãƒ¼ãƒ—ãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
    media_patterns = analysis_result['media_patterns']['pattern_df']
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢
    formatted_data = {
        'summary': {
            'previous': {
                'impressions': previous_total.get('Impressions', 0),
                'clicks': previous_total.get('Clicks', 0),
                'cost': previous_total.get('Cost', 0),
                'conversions': previous_total.get('Conversions', 0),
                'days': previous_days
            },
            'current': {
                'impressions': current_total.get('Impressions', 0),
                'clicks': current_total.get('Clicks', 0),
                'cost': current_total.get('Cost', 0),
                'conversions': current_total.get('Conversions', 0),
                'days': current_days
            }
        },
        'cv_contribution': cv_contribution.to_dict('records'),
        'cpa_change_factors': cpa_change_factors.to_dict('records'),
        'media_patterns': media_patterns.to_dict('records')
    }
    
    return formatted_data

# åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆã™ã‚‹é–¢æ•°
def create_analysis_prompt(data):
    """
    åˆ†æç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆã™ã‚‹
    
    Parameters:
    data (dict): æ•´å½¢ã•ã‚ŒãŸåˆ†æãƒ‡ãƒ¼ã‚¿
    
    Returns:
    str: åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    """
    # ã‚µãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
    summary = data['summary']
    previous = summary['previous']
    current = summary['current']
    
    # å¤‰åŒ–ç‡ã®è¨ˆç®—
    imp_change = ((current['impressions'] - previous['impressions']) / previous['impressions']) * 100 if previous['impressions'] != 0 else float('inf')
    clicks_change = ((current['clicks'] - previous['clicks']) / previous['clicks']) * 100 if previous['clicks'] != 0 else float('inf')
    cost_change = ((current['cost'] - previous['cost']) / previous['cost']) * 100 if previous['cost'] != 0 else float('inf')
    cv_change = ((current['conversions'] - previous['conversions']) / previous['conversions']) * 100 if previous['conversions'] != 0 else float('inf')
    
    # CPAã®è¨ˆç®—
    previous_cpa = previous['cost'] / previous['conversions'] if previous['conversions'] != 0 else 0
    current_cpa = current['cost'] / current['conversions'] if current['conversions'] != 0 else 0
    cpa_change = ((current_cpa - previous_cpa) / previous_cpa) * 100 if previous_cpa != 0 else float('inf')
    
    # æ—¥å¹³å‡å€¤ã®è¨ˆç®—
    previous_daily_cv = previous['conversions'] / previous['days']
    current_daily_cv = current['conversions'] / current['days']
    daily_cv_change = ((current_daily_cv - previous_daily_cv) / previous_daily_cv) * 100 if previous_daily_cv != 0 else float('inf')
    
    # ã‚µãƒãƒªãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«
    summary_table = f"""
| æŒ‡æ¨™ | å‰æœŸ | å½“æœŸ | å·®åˆ† | å¤‰åŒ–ç‡ |
|------|-----|-----|------|--------|
| ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•° | {previous['impressions']:,} | {current['impressions']:,} | {current['impressions'] - previous['impressions']:,} | {imp_change:.1f}% |
| ã‚¯ãƒªãƒƒã‚¯æ•° | {previous['clicks']:,} | {current['clicks']:,} | {current['clicks'] - previous['clicks']:,} | {clicks_change:.1f}% |
| ã‚³ã‚¹ãƒˆ | {previous['cost']:,}å†† | {current['cost']:,}å†† | {current['cost'] - previous['cost']:,}å†† | {cost_change:.1f}% |
| ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•° | {previous['conversions']:,} | {current['conversions']:,} | {current['conversions'] - previous['conversions']:,} | {cv_change:.1f}% |
| CPA | {previous_cpa:,.0f}å†† | {current_cpa:,.0f}å†† | {current_cpa - previous_cpa:,.0f}å†† | {cpa_change:.1f}% |
| æ—¥æ•° | {previous['days']} | {current['days']} | {current['days'] - previous['days']} | - |
| æ—¥å¹³å‡CVæ•° | {previous_daily_cv:.1f} | {current_daily_cv:.1f} | {current_daily_cv - previous_daily_cv:.1f} | {daily_cv_change:.1f}% |
"""
    
    # CVå¢—æ¸›ã®å¯„ä¸åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    cv_contributions = data['cv_contribution'][:5]  # ä¸Šä½5ä»¶
    
    cv_table = "| é †ä½ | åª’ä½“å | å‰æœŸCVæ•° | å½“æœŸCVæ•° | CVæ•°å¤‰åŒ– | å¯„ä¸ç‡(%) |\n|------|------|------|------|------|------|\n"
    
    for i, item in enumerate(cv_contributions, 1):
        media_name = item.get('ServiceNameJA', 'Unknown')
        previous_cv = item.get('previous_cv', 0)
        current_cv = item.get('current_cv', 0)
        cv_change = item.get('cv_change', 0)
        contribution_rate = item.get('contribution_rate', 0)
        
        cv_table += f"| {i} | {media_name} | {previous_cv:.0f} | {current_cv:.0f} | {cv_change:.0f} | {contribution_rate:.1f}% |\n"
    
    # CPAå¤‰åŒ–è¦å› åˆ†æ
    cpa_factors = data['cpa_change_factors'][:5]  # ä¸Šä½5ä»¶
    
    cpa_table = "| åª’ä½“å | å‰æœŸCPA | å½“æœŸCPA | CPAå¤‰åŒ–ç‡ | ä¸»è¦å›  | å‰¯è¦å›  |\n|------|------|------|------|------|------|\n"
    
    for item in cpa_factors:
        media_name = item.get('ServiceNameJA', 'Unknown')
        previous_cpa = item.get('previous_cpa', 0)
        current_cpa = item.get('current_cpa', 0)
        cpa_change_rate = item.get('cpa_change_rate', 0)
        main_factor = item.get('main_factor', 'Unknown')
        secondary_factor = item.get('secondary_factor', '-')
        
        cpa_table += f"| {media_name} | {previous_cpa:.0f}å†† | {current_cpa:.0f}å†† | {cpa_change_rate:.1f}% | {main_factor} | {secondary_factor} |\n"
    
    # åª’ä½“ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
    pattern_counts = {}
    for item in data['media_patterns']:
        pattern = item.get('pattern', 'unknown')
        if pattern in pattern_counts:
            pattern_counts[pattern] += 1
        else:
            pattern_counts[pattern] = 1
    
    pattern_summary = "åª’ä½“ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†é¡:\n"
    pattern_summary += f"- æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆCVå¢—åŠ ã‹ã¤CPAæ”¹å–„ï¼‰: {pattern_counts.get('success', 0)}åª’ä½“\n"
    pattern_summary += f"- æˆé•·é‡è¦–ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆCVå¢—åŠ ã‹ã¤CPAæ‚ªåŒ–ï¼‰: {pattern_counts.get('growth', 0)}åª’ä½“\n"
    pattern_summary += f"- åŠ¹ç‡é‡è¦–ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆCVæ¸›å°‘ã‹ã¤CPAæ”¹å–„ï¼‰: {pattern_counts.get('efficiency', 0)}åª’ä½“\n"
    pattern_summary += f"- èª²é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆCVæ¸›å°‘ã‹ã¤CPAæ‚ªåŒ–ï¼‰: {pattern_counts.get('issue', 0)}åª’ä½“\n"
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆ
    prompt = f"""# åºƒå‘Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ

## å…¨ä½“ã‚µãƒãƒªãƒ¼
{summary_table}

## CVå¢—æ¸›ã®å¯„ä¸åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆä¸Šä½5åª’ä½“ï¼‰
{cv_table}

## CPAå¤‰åŒ–è¦å› åˆ†æï¼ˆä¸Šä½5åª’ä½“ï¼‰
{cpa_table}

## åª’ä½“ã‚°ãƒ«ãƒ¼ãƒ—ãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
{pattern_summary}

---

ä¸Šè¨˜ã®åºƒå‘Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€ä»¥ä¸‹ã®å†…å®¹ã‚’å«ã‚€ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š

1. å…¨ä½“ã‚µãƒãƒªãƒ¼
   - ä¸»è¦æŒ‡æ¨™ã®å¤‰åŒ–çŠ¶æ³
   - æ—¥æ•°å·®ã‚’è€ƒæ…®ã—ãŸå ´åˆã®è©•ä¾¡

2. CVå¢—æ¸›ã®å¯„ä¸åº¦åˆ†æ
   - CVå¢—æ¸›ã«å¤§ããå½±éŸ¿ã—ãŸåª’ä½“ã®ç‰¹å®š
   - å¯„ä¸ç‡ã®é«˜ã„åª’ä½“ã®å‹•å‘åˆ†æ

3. CPAå¤‰åŒ–è¦å› åˆ†æ
   - ä¸»ãªCPAå¤‰åŒ–ã®è¦å› ï¼ˆCVRã¾ãŸã¯CPCï¼‰
   - å¤‰åŒ–ã®è©³ç´°èª¬æ˜

4. æˆ¦ç•¥çš„å¤‰åŒ–ã®è§£é‡ˆ
   - åª’ä½“ã‚¿ã‚¤ãƒ—é–“ã®äºˆç®—ã‚·ãƒ•ãƒˆåˆ†æ
   - åŠ¹ç‡ã¨è¦æ¨¡ã®ãƒãƒ©ãƒ³ã‚¹å¤‰åŒ–
   - æ–°è¦å°å…¥ã¾ãŸã¯ç¸®å°ã•ã‚ŒãŸåª’ä½“ã®è©•ä¾¡

5. é‡ç‚¹çš„ã«è¦‹ã‚‹ã¹ãå•é¡Œç‚¹ã¨æ©Ÿä¼š
   - å„ªå…ˆçš„ã«å¯¾å¿œã™ã¹ã3ã¤ã®èª²é¡Œ
   - æ´»ç”¨ã™ã¹ã3ã¤ã®å¥½æ©Ÿ
   - å„é …ç›®ã«å¯¾ã™ã‚‹æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³

ä»¥ä¸‹ã®æ³¨æ„ç‚¹ã‚’è€ƒæ…®ã—ã¦ãã ã•ã„ï¼š
- å˜ç´”ãªæ•°å€¤æ¯”è¼ƒã ã‘ã§ãªãã€èƒŒæ™¯ã«ã‚ã‚‹æˆ¦ç•¥çš„æ„å›³ã‚’è€ƒæ…®
- æ—¥æ•°ã®é•ã„ãŒã‚ã‚‹å ´åˆã¯ã€æ—¥å¹³å‡å€¤ã§ã®æ¯”è¼ƒã‚‚æ¤œè¨
- CVæ•°ãŒæ¥µç«¯ã«å°‘ãªã„åª’ä½“ï¼ˆ5ä»¶æœªæº€ç­‰ï¼‰ã¯CPAç­‰ã®å¤‰å‹•ãŒå¤§ãããªã‚‹ãŸã‚è§£é‡ˆã«æ³¨æ„
- æ–°è¦è¿½åŠ ã‚„åœæ­¢ã•ã‚ŒãŸåª’ä½“ã«ã¤ã„ã¦ã¯ã€ç‰¹åˆ¥ã«è¨€åŠ
- å­£ç¯€æ€§ã‚„å¸‚å ´ç’°å¢ƒå¤‰åŒ–ãªã©ã€å¤–éƒ¨è¦å› ã®å¯èƒ½æ€§ã‚‚è€ƒæ…®
"""
    
    return prompt

# ChatGPTã‚’ä½¿ç”¨ã—ãŸåˆ†æçµæœã®è§£é‡ˆ
def interpret_analysis_with_chatgpt(analysis_result, api_key, model="gpt-3.5-turbo-16k"):
    """
    åˆ†æçµæœã‚’ChatGPT APIã‚’ä½¿ç”¨ã—ã¦è§£é‡ˆã™ã‚‹
    
    Parameters:
    analysis_result (dict): åˆ†æçµæœ
    api_key (str): OpenAI API Key
    model (str): ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
    
    Returns:
    dict: ChatGPTã®è§£é‡ˆçµæœ
    """
    if not api_key:
        st.warning("OpenAI API KeyãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚åˆ†æçµæœã®è§£é‡ˆã‚’è¡Œã†ã«ã¯API Keyã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return None
    
    try:
        # OpenAI APIã®è¨­å®š
        openai.api_key = api_key
        
        # åˆ†æçµæœã®æ•´å½¢
        prompt_data = format_prompt_data(analysis_result)
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆ
        prompt = create_analysis_prompt(prompt_data)
        
        # ChatGPT APIã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        response = openai.ChatCompletion.create(
            model=model,
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯åºƒå‘Šãƒ‡ãƒ¼ã‚¿åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®æŒ‡ç¤ºã«å¾“ã£ã¦åºƒå‘Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€æ´å¯Ÿã¨æ¨å¥¨äº‹é …ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.5,
            max_tokens=4000
        )
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å–å¾—
        interpretation = response.choices[0].message.content
        
        return {
            'interpretation': interpretation,
            'prompt': prompt
        }
    
    except Exception as e:
        st.error(f"ChatGPT APIã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return None

# ãƒ¡ã‚¤ãƒ³æ©Ÿèƒ½ã®å®Ÿè£…
def main():
    # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒˆãƒ«
    st.title("åºƒå‘Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã‚·ã‚¹ãƒ†ãƒ ")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¨­å®š
    st.sidebar.title("åˆ†æè¨­å®š")
    
    # Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®æ¥ç¶šæƒ…å ±
    default_url = "https://docs.google.com/spreadsheets/d/1dKjwuk5kOL1bK2KUwZuPMF4sG_aGZt1x4tK6_ooYZv0/edit?gid=1161532243#gid=1161532243"
    default_sheet = "åŸºæœ¬ãƒ‡ãƒ¼ã‚¿"
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿è¨­å®š
    with st.sidebar.expander("ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹è¨­å®š", expanded=True):
        spreadsheet_url = st.text_input("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆURL", value=default_url)
        sheet_name = st.text_input("ã‚·ãƒ¼ãƒˆå", value=default_sheet)
        
        if st.button("ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"):
            df = load_data_from_gsheet(spreadsheet_url, sheet_name)
            if df is not None:
                # æ´¾ç”ŸæŒ‡æ¨™ã®è¨ˆç®—
                df = calculate_derived_metrics(df)
                st.session_state['data'] = df
                st.success("ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            else:
                st.error("ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    # ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
    if 'data' not in st.session_state or st.session_state['data'] is None:
        st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ãã ã•ã„")
        return
    
    # ãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦ã‚’è¡¨ç¤º
    df = st.session_state['data']
    
    # ã‚¿ãƒ–ã®è¨­å®š
    tab1, tab2, tab3 = st.tabs(["ãƒ‡ãƒ¼ã‚¿æ¦‚è¦", "æœŸé–“æ¯”è¼ƒåˆ†æ", "ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›"])
    
    # ã‚¿ãƒ–1: ãƒ‡ãƒ¼ã‚¿æ¦‚è¦
    with tab1:
        st.header("ãƒ‡ãƒ¼ã‚¿æ¦‚è¦")
        
        # ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬æƒ…å ±
        st.subheader("åŸºæœ¬æƒ…å ±")
        st.write(f"è¡Œæ•°: {len(df)}, åˆ—æ•°: {len(df.columns)}")
        
        # æ—¥ä»˜ç¯„å›²ã®è¡¨ç¤º
        if 'Date' in df.columns:
            min_date = df['Date'].min()
            max_date = df['Date'].max()
            st.write(f"ãƒ‡ãƒ¼ã‚¿æœŸé–“: {min_date.strftime('%Y-%m-%d')} ã‹ã‚‰ {max_date.strftime('%Y-%m-%d')} ({(max_date - min_date).days + 1} æ—¥é–“)")
        
        # åª’ä½“æ•°ã®è¡¨ç¤º
        if 'ServiceNameJA' in df.columns:
            media_count = df['ServiceNameJA'].nunique()
            st.write(f"åª’ä½“æ•°: {media_count}")
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
        st.subheader("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿")
        st.dataframe(df.head(10))
        
        # æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤ºï¼ˆæŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•ï¼‰
        if 'Date' in df.columns:
            st.subheader("æ—¥æ¬¡æ¨ç§»")
            
            # ã‚°ãƒ©ãƒ•é¸æŠ
            metric_option = st.selectbox(
                "æŒ‡æ¨™é¸æŠ",
                ["Impressions", "Clicks", "Cost", "Conversions", "CTR", "CVR", "CPC", "CPA", "CPM"],
                index=3  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯Conversions
            )
            
            # æ—¥æ¬¡é›†è¨ˆ
            daily_df = df.groupby('Date')[metric_option].sum().reset_index()
            
            # ã‚°ãƒ©ãƒ•ä½œæˆ
            fig = px.line(
                daily_df,
                x='Date',
                y=metric_option,
                title=f"{metric_option}ã®æ—¥æ¬¡æ¨ç§»",
                labels={'Date': 'æ—¥ä»˜', metric_option: metric_option}
            )
            
            # Yãƒ©ãƒ™ãƒ«ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆèª¿æ•´
            if metric_option in ['CTR', 'CVR']:
                fig.update_layout(yaxis_ticksuffix='%')
            elif metric_option in ['Cost', 'CPC', 'CPA']:
                fig.update_layout(yaxis_ticksuffix='å††')
            
            st.plotly_chart(fig, use_container_width=True)
        
        # åª’ä½“åˆ¥ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤ºï¼ˆå††ã‚°ãƒ©ãƒ•ï¼‰
        if 'ServiceNameJA' in df.columns:
            st.subheader("åª’ä½“åˆ¥ãƒ‡ãƒ¼ã‚¿")
            
            # ã‚°ãƒ©ãƒ•é¸æŠ
            media_metric = st.selectbox(
                "æŒ‡æ¨™é¸æŠï¼ˆåª’ä½“åˆ¥ï¼‰",
                ["Impressions", "Clicks", "Cost", "Conversions"],
                index=2  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯Cost
            )
            
            # åª’ä½“åˆ¥é›†è¨ˆ
            media_df = df.groupby('ServiceNameJA')[media_metric].sum().reset_index()
            
            # ä¸Šä½10åª’ä½“ã«çµã‚‹
            media_df = media_df.sort_values(media_metric, ascending=False).head(10)
            
            # ã‚°ãƒ©ãƒ•ä½œæˆ
            fig = px.pie(
                media_df,
                values=media_metric,
                names='ServiceNameJA',
                title=f"åª’ä½“åˆ¥ {media_metric} æ§‹æˆæ¯”ï¼ˆä¸Šä½10åª’ä½“ï¼‰"
            )
            fig.update_traces(textposition='inside', textinfo='percent+label')
            
            st.plotly_chart(fig, use_container_width=True)
    
    # ã‚¿ãƒ–2: æœŸé–“æ¯”è¼ƒåˆ†æ
    with tab2:
        st.header("æœŸé–“æ¯”è¼ƒåˆ†æ")
        
        # æœŸé–“è¨­å®š
        st.subheader("æœŸé–“è¨­å®š")
        
        # åˆ†æå˜ä½ã®é¸æŠ
        analysis_unit = st.radio(
            "åˆ†æå˜ä½",
            ["æœˆæ¬¡", "é€±æ¬¡", "ã‚«ã‚¹ã‚¿ãƒ "],
            horizontal=True
        )
        
        # æ—¥ä»˜ç¯„å›²ã®å–å¾—
        if 'Date' in df.columns:
            min_date = df['Date'].min()
            max_date = df['Date'].max()
        else:
            min_date = datetime.now() - timedelta(days=60)
            max_date = datetime.now()
        
        # æœŸé–“è¨­å®šUI
        if analysis_unit == "æœˆæ¬¡":
            # æœˆæ¬¡åˆ†æç”¨ã®æœŸé–“è¨­å®š
            months = []
            current_date = min_date
            while current_date <= max_date:
                months.append(current_date.strftime("%Y-%m"))
                # æ¬¡ã®æœˆã®åˆæ—¥ã«ç§»å‹•
                if current_date.month == 12:
                    current_date = datetime(current_date.year + 1, 1, 1)
                else:
                    current_date = datetime(current_date.year, current_date.month + 1, 1)
            
            # é‡è¤‡ã‚’å‰Šé™¤ã—ã€ã‚½ãƒ¼ãƒˆ
            months = sorted(list(set(months)))
            
            if len(months) < 2:
                st.warning("æœˆæ¬¡åˆ†æã‚’è¡Œã†ã«ã¯ã€å°‘ãªãã¨ã‚‚2ã¤ã®ç•°ãªã‚‹æœˆã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™")
                return
            
            # æœˆã®é¸æŠ
            col1, col2 = st.columns(2)
            with col1:
                previous_month = st.selectbox("å‰æœŸï¼ˆæœˆï¼‰", months[:-1], index=len(months)-2)
            with col2:
                current_month = st.selectbox("å½“æœŸï¼ˆæœˆï¼‰", months[1:], index=len(months)-2)
            
            # é¸æŠã•ã‚ŒãŸæœˆã®é–‹å§‹æ—¥ã¨çµ‚äº†æ—¥ã‚’è¨ˆç®—
            previous_year, previous_month_num = map(int, previous_month.split('-'))
            previous_start = datetime(previous_year, previous_month_num, 1)
            if previous_month_num == 12:
                previous_end = datetime(previous_year + 1, 1, 1) - timedelta(days=1)
            else:
                previous_end = datetime(previous_year, previous_month_num + 1, 1) - timedelta(days=1)
            
            current_year, current_month_num = map(int, current_month.split('-'))
            current_start = datetime(current_year, current_month_num, 1)
            if current_month_num == 12:
                current_end = datetime(current_year + 1, 1, 1) - timedelta(days=1)
            else:
                current_end = datetime(current_year, current_month_num + 1, 1) - timedelta(days=1)
        
        elif analysis_unit == "é€±æ¬¡":
            # é€±æ¬¡åˆ†æç”¨ã®æœŸé–“è¨­å®š
            # é€±ã®é–‹å§‹æ—¥ã‚’æœˆæ›œæ—¥ã¨ã™ã‚‹
            start_of_week = min_date - timedelta(days=min_date.weekday())
            
            weeks = []
            current_date = start_of_week
            while current_date <= max_date:
                week_end = current_date + timedelta(days=6)
                weeks.append((current_date, week_end))
                current_date = current_date + timedelta(days=7)
            
            # é€±ã®é¸æŠè‚¢ã‚’ä½œæˆ
            week_options = [f"{week[0].strftime('%m/%d')}ï½{week[1].strftime('%m/%d')}" for week in weeks]
            
            if len(week_options) < 2:
                st.warning("é€±æ¬¡åˆ†æã‚’è¡Œã†ã«ã¯ã€å°‘ãªãã¨ã‚‚2é€±é–“ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™")
                return
            
            # é€±ã®é¸æŠ
            col1, col2 = st.columns(2)
            with col1:
                previous_week_idx = st.selectbox("å‰é€±", week_options[:-1], index=len(week_options)-2)
            with col2:
                current_week_idx = st.selectbox("å½“é€±", week_options[1:], index=len(week_options)-2)
            
            # é¸æŠã•ã‚ŒãŸé€±ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
            previous_week_idx = week_options.index(previous_week_idx)
            current_week_idx = week_options.index(current_week_idx)
            
            # æ—¥ä»˜ç¯„å›²ã‚’è¨­å®š
            previous_start, previous_end = weeks[previous_week_idx]
            current_start, current_end = weeks[current_week_idx]
        
        else:  # ã‚«ã‚¹ã‚¿ãƒ 
            # ã‚«ã‚¹ã‚¿ãƒ æœŸé–“è¨­å®š
            col1, col2 = st.columns(2)
            with col1:
                st.write("å‰æœŸ")
                previous_start = st.date_input(
                    "é–‹å§‹æ—¥",
                    value=min_date,
                    min_value=min_date,
                    max_value=max_date
                )
                previous_end = st.date_input(
                    "çµ‚äº†æ—¥",
                    value=min_date + timedelta(days=6),
                    min_value=previous_start,
                    max_value=max_date
                )
            
            with col2:
                st.write("å½“æœŸ")
                current_start = st.date_input(
                    "é–‹å§‹æ—¥",
                    value=previous_end + timedelta(days=1),
                    min_value=min_date,
                    max_value=max_date
                )
                current_end = st.date_input(
                    "çµ‚äº†æ—¥",
                    value=min(current_start + timedelta(days=6), max_date),
                    min_value=current_start,
                    max_value=max_date
                )
        
        # é¸æŠã•ã‚ŒãŸæœŸé–“ã‚’è¡¨ç¤º
        st.write(f"å‰æœŸ: {previous_start.strftime('%Y-%m-%d')} ã‹ã‚‰ {previous_end.strftime('%Y-%m-%d')} ({(previous_end - previous_start).days + 1} æ—¥é–“)")
        st.write(f"å½“æœŸ: {current_start.strftime('%Y-%m-%d')} ã‹ã‚‰ {current_end.strftime('%Y-%m-%d')} ({(current_end - current_start).days + 1} æ—¥é–“)")
        
        # åˆ†æç²’åº¦ã®é¸æŠ
        st.subheader("åˆ†æç²’åº¦")
        
        # åˆ©ç”¨å¯èƒ½ãªã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã‚«ãƒ©ãƒ ã®ç¢ºèª
        group_columns = ['ServiceNameJA']
        if 'CampaignName' in df.columns:
            group_columns.append('CampaignName')
        if 'AdgroupName' in df.columns and df['AdgroupName'].notna().any():
            group_columns.append('AdgroupName')
        
        analysis_granularity = st.selectbox(
            "åˆ†æç²’åº¦",
            group_columns,
            index=0
        )
        
        # OpenAI API Keyã®è¨­å®š
        st.subheader("åˆ†æè¨­å®š")
        
        openai_api_key = st.text_input("OpenAI API Key (ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«å¿…è¦)", type="password")
        
        # åˆ†æå®Ÿè¡Œãƒœã‚¿ãƒ³
        if st.button("åˆ†æå®Ÿè¡Œ"):
            with st.spinner("åˆ†æã‚’å®Ÿè¡Œä¸­..."):
                # å‰æœŸãƒ»å½“æœŸã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                previous_df = filter_data_by_date(df, previous_start, previous_end)
                current_df = filter_data_by_date(df, current_start, current_end)
                
                # åˆ†æç²’åº¦ã«åŸºã¥ã„ã¦ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã‚«ãƒ©ãƒ ã‚’è¨­å®š
                if analysis_granularity == 'ServiceNameJA':
                    group_by_cols = ['ServiceNameJA']
                elif analysis_granularity == 'CampaignName':
                    group_by_cols = ['ServiceNameJA', 'CampaignName']
                elif analysis_granularity == 'AdgroupName':
                    group_by_cols = ['ServiceNameJA', 'CampaignName', 'AdgroupName']
                
                # æœŸé–“æ¯”è¼ƒåˆ†æã‚’å®Ÿè¡Œ
                analysis_result = compare_periods(current_df, previous_df, group_by_cols)
                
                if analysis_result:
                    st.session_state['analysis_result'] = analysis_result
                    
                    # ChatGPTã«ã‚ˆã‚‹åˆ†æçµæœã®è§£é‡ˆï¼ˆAPI KeyãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
                    if openai_api_key:
                        with st.spinner("ChatGPTã«ã‚ˆã‚‹åˆ†æçµæœã®è§£é‡ˆä¸­..."):
                            try:
                                interpretation = interpret_analysis_with_chatgpt(analysis_result, openai_api_key)
                                if interpretation:
                                    st.session_state['interpretation'] = interpretation
                                    st.success("åˆ†æå®Œäº†ï¼ã€Œãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ã€ã‚¿ãƒ–ã§çµæœã‚’ç¢ºèªã§ãã¾ã™")
                                else:
                                    st.warning("ChatGPTã«ã‚ˆã‚‹åˆ†æçµæœã®è§£é‡ˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                            except Exception as e:
                                st.error(f"ChatGPT APIã¨ã®é€šä¿¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                    else:
                        st.warning("OpenAI API KeyãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™")
                        st.success("åˆ†æå®Œäº†ï¼ã€Œãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ã€ã‚¿ãƒ–ã§çµæœã‚’ç¢ºèªã§ãã¾ã™")
                else:
                    st.error("åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        # åˆ†æçµæœãŒã‚ã‚Œã°è¡¨ç¤º
        if 'analysis_result' in st.session_state and st.session_state['analysis_result']:
            result = st.session_state['analysis_result']
            
            st.subheader("åˆ†æçµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
            
            # 1. å…¨ä½“ã‚µãƒãƒªãƒ¼
            st.write("#### å…¨ä½“ã‚µãƒãƒªãƒ¼")
            col1, col2, col3 = st.columns(3)
            
            # å‰æœŸãƒ»å½“æœŸã®åˆè¨ˆå€¤
            current_total = result['current_total']
            previous_total = result['previous_total']
            
            # å„æŒ‡æ¨™ã®å¤‰åŒ–ç‡ã‚’è¨ˆç®—
            cv_change = ((current_total['Conversions'] - previous_total['Conversions']) / previous_total['Conversions']) * 100 if previous_total['Conversions'] != 0 else 0
            cost_change = ((current_total['Cost'] - previous_total['Cost']) / previous_total['Cost']) * 100 if previous_total['Cost'] != 0 else 0
            
            # CPAã®è¨ˆç®—
            previous_cpa = previous_total['Cost'] / previous_total['Conversions'] if previous_total['Conversions'] != 0 else 0
            current_cpa = current_total['Cost'] / current_total['Conversions'] if current_total['Conversions'] != 0 else 0
            cpa_change = ((current_cpa - previous_cpa) / previous_cpa) * 100 if previous_cpa != 0 else 0
            
            with col1:
                st.metric(
                    "ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³",
                    f"{current_total['Conversions']:,.0f}",
                    f"{cv_change:.1f}%"
                )
            
            with col2:
                st.metric(
                    "ã‚³ã‚¹ãƒˆ",
                    f"{current_total['Cost']:,.0f}å††",
                    f"{cost_change:.1f}%"
                )
            
            with col3:
                st.metric(
                    "CPA",
                    f"{current_cpa:,.0f}å††",
                    f"{cpa_change:.1f}%",
                    delta_color="inverse" # CPAã¯ä¸‹ãŒã‚‹æ–¹ãŒãƒ—ãƒ©ã‚¹è¡¨ç¤º
                )
            
            # 2. CVå¢—æ¸›ã®å¯„ä¸åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°
            st.write("#### CVå¢—æ¸›ã®å¯„ä¸åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
            
            cv_contribution = result['cv_contribution'].head(5)
            st.dataframe(cv_contribution)
            
            # 3. CPAå¤‰åŒ–è¦å› åˆ†æ
            st.write("#### CPAå¤‰åŒ–è¦å› åˆ†æ")
            
            cpa_factors = result['cpa_change_factors'].head(5)
            st.dataframe(cpa_factors)
            
            # 4. åª’ä½“ã‚°ãƒ«ãƒ¼ãƒ—ãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
            st.write("#### åª’ä½“ã‚°ãƒ«ãƒ¼ãƒ—ãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ")
            
            patterns = result['media_patterns']['pattern_df']
            pattern_counts = patterns['pattern'].value_counts()
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†å¸ƒã®å††ã‚°ãƒ©ãƒ•
            fig = px.pie(
                pattern_counts,
                values=pattern_counts.values,
                names=pattern_counts.index,
                title="åª’ä½“ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†å¸ƒ",
                labels={
                    'index': 'ãƒ‘ã‚¿ãƒ¼ãƒ³',
                    'value': 'åª’ä½“æ•°'
                }
            )
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³åã‚’æ—¥æœ¬èªã«å¤‰æ›
            pattern_names = {
                'success': 'æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆCVå¢—åŠ ã‹ã¤CPAæ”¹å–„ï¼‰',
                'growth': 'æˆé•·é‡è¦–ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆCVå¢—åŠ ã‹ã¤CPAæ‚ªåŒ–ï¼‰',
                'efficiency': 'åŠ¹ç‡é‡è¦–ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆCVæ¸›å°‘ã‹ã¤CPAæ”¹å–„ï¼‰',
                'issue': 'èª²é¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆCVæ¸›å°‘ã‹ã¤CPAæ‚ªåŒ–ï¼‰'
            }
            
            fig.update_traces(
                labels=[pattern_names.get(p, p) for p in pattern_counts.index],
                textinfo='percent+label'
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    # ã‚¿ãƒ–3: ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
    with tab3:
        st.header("ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›")
        
        # åˆ†æçµæœãŒã‚ã‚‹ã‹ç¢ºèª
        if 'analysis_result' not in st.session_state or not st.session_state['analysis_result']:
            st.info("ã€ŒæœŸé–“æ¯”è¼ƒåˆ†æã€ã‚¿ãƒ–ã§åˆ†æã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
            return
        
        # ChatGPTã«ã‚ˆã‚‹è§£é‡ˆçµæœãŒã‚ã‚‹ã‹ç¢ºèª
        if 'interpretation' in st.session_state and st.session_state['interpretation']:
            interpretation = st.session_state['interpretation']
            
            # ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
            st.subheader("åºƒå‘Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
            
            # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã§ãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤º
            st.markdown(interpretation['interpretation'])
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¡¨ç¤ºã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³
            with st.expander("åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆé–‹ç™ºè€…ç”¨ï¼‰"):
                st.code(interpretation['prompt'], language="markdown")
            
            # ãƒ¬ãƒãƒ¼ãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            report_text = interpretation['interpretation']
            
            # ãƒ¬ãƒãƒ¼ãƒˆã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ
            report_download = f"""# åºƒå‘Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æãƒ¬ãƒãƒ¼ãƒˆ

{report_text}
            """
            
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            st.download_button(
                label="ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=report_download,
                file_name="åºƒå‘Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æãƒ¬ãƒãƒ¼ãƒˆ.md",
                mime="text/markdown"
            )
        else:
            st.warning("ChatGPTã«ã‚ˆã‚‹åˆ†æãƒ¬ãƒãƒ¼ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚OpenAI API Keyã‚’è¨­å®šã—ã¦åˆ†æã‚’å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            
            # æ‰‹å‹•ã§ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¡¨ç¤º
            st.subheader("æ‰‹å‹•ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
            if 'analysis_result' in st.session_state:
                prompt_data = format_prompt_data(st.session_state['analysis_result'])
                prompt = create_analysis_prompt(prompt_data)
                
                st.code(prompt, language="markdown")
                
                st.info("ä¸Šè¨˜ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ChatGPTã«å…¥åŠ›ã™ã‚‹ã“ã¨ã§ã€æ‰‹å‹•ã§ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã§ãã¾ã™ã€‚")

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œ
if __name__ == "__main__":
    main()
